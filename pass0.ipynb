{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de1bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall tensorflow --yes\n",
    "\n",
    "# this and the next cells to make sure we use latest releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9260c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall keras --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7756c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81792e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 21:22:49.689743: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 21:22:50.344292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bbfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd1c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (replace this with your actual dataset)\n",
    "#  100 data samples, each having 64 features. \n",
    "data = np.random.rand(100, 64)  # Assuming 100 data samples with 64 features each\n",
    "\n",
    "# Step 1: Create and train the autoencoder\n",
    "input_dim = data.shape[1]\n",
    "# Sets input_dim to the number of features in the data: 64 \n",
    "latent_dim = 32  # Adjust this according to your desired latent space size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84434ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 21:22:51.183484: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-21 21:22:51.183549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: joepareti54-GS75-Stealth-9SE\n",
      "2023-07-21 21:22:51.183556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: joepareti54-GS75-Stealth-9SE\n",
      "2023-07-21 21:22:51.183674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 530.41.3\n",
      "2023-07-21 21:22:51.183704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 530.41.3\n",
      "2023-07-21 21:22:51.183709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 530.41.3\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "input_data = Input(shape=(input_dim,))\n",
    "#\n",
    "# Defines the input layer of the autoencoder with the shape (input_dim,), \n",
    "# which accepts data samples with 64 features each.\n",
    "#\n",
    "encoded = Dense(latent_dim, activation='relu')(input_data)\n",
    "#\n",
    "#Defines the encoder part of the autoencoder. It takes the input data and\n",
    "#applies a dense (fully connected) layer with latent_dim neurons\n",
    "#and a ReLU activation function to compress the data into the latent space.\n",
    "#\n",
    "encoder = Model(input_data, encoded)\n",
    "#Creates the encoder model using the Model class with the input as input_data and \n",
    "#the output as encoded. This forms the encoder part of the autoencoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205e0888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "# Defines the input layer of the decoder \n",
    "#with the shape (latent_dim,), \n",
    "#which accepts data samples with 32 features \n",
    "#(matching the size of the latent space).\n",
    "#\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoder_input)\n",
    "#Defines the decoder part of the autoencoder. \n",
    "#It takes the compressed data from the encoder (decoder_input) \n",
    "#and applies a dense layer with input_dim neurons and \n",
    "#a hyperbolic tangent (tanh) activation function \n",
    "#to reconstruct the original data.\n",
    "#\n",
    "decoder = Model(decoder_input, decoded)\n",
    "#Creates the decoder model using the Model class with the input \n",
    "#as decoder_input and the output as decoded.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1b031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 32)                2080      \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 64)                2112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4192 (16.38 KB)\n",
      "Trainable params: 4192 (16.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder (combination of encoder and decoder)\n",
    "autoencoder_input = Input(shape=(input_dim,))\n",
    "# Defines the input layer for the autoencoder with the shape \n",
    "# (input_dim,), which accepts data samples with 64 features each.\n",
    "autoencoder_encoded = encoder(autoencoder_input)\n",
    "# Applies the encoder model (encoder) to the input data to get \n",
    "#the compressed representation in the latent space.\n",
    "#\n",
    "autoencoder_decoded = decoder(autoencoder_encoded)\n",
    "# Applies the decoder model (decoder) to the compressed \n",
    "# representation to reconstruct the original data.\n",
    "#\n",
    "autoencoder = Model(autoencoder_input, autoencoder_decoded)\n",
    "# Creates the complete autoencoder model using the \n",
    "# Model class with the input as autoencoder_input and \n",
    "# the output as autoencoder_decoded.\n",
    "#\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4286c702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0930\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0893\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0870\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0855\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0845\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0839\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0834\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0829\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0826\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0824\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0822\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0820\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0818\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0816\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0815\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0813\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0811\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0809\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0807\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0804\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0802\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0800\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0797\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0795\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0792\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0790\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0787\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0785\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0782\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0779\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0776\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0772\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0769\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0766\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0762\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0759\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0755\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0752\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0749\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0745\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0737\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0734\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0730\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0727\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0723\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0715\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0711\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fecd65a3310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(data, data, epochs=50, batch_size=32)\n",
    "#Trains the autoencoder using the fit method with data \n",
    "#as both the input and output (since it is an autoencoder). \n",
    "# The autoencoder is trained for 50 epochs with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffcc4491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 862us/step\n",
      "4/4 [==============================] - 0s 841us/step\n",
      "Original Data Shape: (100, 64)\n",
      "Perturbed Data Shape: (100, 64)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Obtain the latent space representation\n",
    "latent_representation = encoder.predict(data)\n",
    "# After training the autoencoder, this step obtains the \n",
    "# compressed representation (latent space) of the input data \n",
    "# using the encoder model.\n",
    "\n",
    "# Step 3: Apply Perturbation\n",
    "epsilon = 0.1  # Adjust the perturbation strength as needed\n",
    "epsilon = 0.0\n",
    "perturbation = np.random.uniform(-epsilon, epsilon, size=latent_representation.shape)\n",
    "perturbed_latent_representation = latent_representation + perturbation\n",
    "# Applies the perturbation to the latent space representation \n",
    "# to create a perturbed latent space.\n",
    "#\n",
    "# Step 4: Decode Perturbed Latent Representations\n",
    "perturbed_data = decoder.predict(perturbed_latent_representation)\n",
    "# Decodes the perturbed latent space representation using \n",
    "# the decoder model to obtain the perturbed data. \n",
    "# The decoder maps the perturbed latent space back to the original data space.\n",
    "#\n",
    "# Step 5: Observe the Results\n",
    "# Compare the perturbed_data with the original data to observe the impact of perturbations.\n",
    "print(\"Original Data Shape:\", data.shape)\n",
    "print(\"Perturbed Data Shape:\", perturbed_data.shape)\n",
    "# The code then prints the shapes of the original data and \n",
    "# the perturbed data to observe the impact of the perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8310398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05925131 0.32499617 0.79758326 ... 0.62563696 0.93915596 0.89899897]\n",
      " [0.40866064 0.90505149 0.48497801 ... 0.32777383 0.46564943 0.52200889]\n",
      " [0.3109939  0.26114969 0.7439169  ... 0.07993909 0.79106413 0.83646685]\n",
      " ...\n",
      " [0.76416097 0.65446779 0.16577043 ... 0.34411686 0.55202363 0.73164175]\n",
      " [0.39115989 0.95446798 0.10611404 ... 0.05872074 0.76033107 0.17118192]\n",
      " [0.98650528 0.64255723 0.8388376  ... 0.85932459 0.92463918 0.4511323 ]]\n"
     ]
    }
   ],
   "source": [
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9217484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46602824 0.41471514 0.42414075 ... 0.50805926 0.7086074  0.57131517]\n",
      " [0.45813963 0.4943963  0.42384756 ... 0.5560524  0.64045507 0.5520639 ]\n",
      " [0.47869372 0.4495801  0.45897588 ... 0.4608359  0.47061217 0.541848  ]\n",
      " ...\n",
      " [0.47564748 0.59807605 0.44935754 ... 0.5187882  0.45933253 0.5661952 ]\n",
      " [0.44187322 0.6026424  0.44098148 ... 0.50940776 0.5067764  0.48579106]\n",
      " [0.47676736 0.43748862 0.6706972  ... 0.49686617 0.61880803 0.49802032]]\n"
     ]
    }
   ],
   "source": [
    "print(perturbed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
